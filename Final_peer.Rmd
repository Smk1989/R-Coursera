---
title: "Peer Assessment II"
output:
  html_document: 
    pandoc_args: [
      "--number-sections",
    ]
---

# Background

As a statistical consultant working for a real estate investment firm, your task is to develop a model to predict the selling price of a given home in Ames, Iowa. Your employer hopes to use this information to help assess whether the asking price of a house is higher or lower than the true value of the house. If the home is undervalued, it may be a good investment for the firm.

# Training Data and relevant packages

In order to better assess the quality of the model you will produce, the data have been randomly divided into three separate pieces: a training data set, a testing data set, and a validation data set. For now we will load the training data set, the others will be loaded and used later.

```{r load, message = FALSE}
load("ames_train.Rdata")
```

Use the code block below to load any necessary packages

```{r packages, message = FALSE}
library(statsr)
library(dplyr)
library(BAS)
library(ggplot2)
library(knitr)
```

## Part 1 - Exploratory Data Analysis (EDA)

When you first get your data, it's very tempting to immediately begin fitting models and assessing how they perform.  However, before you begin modeling, it's absolutely essential to explore the structure of the data and the relationships between the variables in the data set.

Do a detailed EDA of the ames_train data set, to learn about the structure of the data and the relationships between the variables in the data set (refer to Introduction to Probability and Data, Week 2, for a reminder about EDA if needed). Your EDA should involve creating and reviewing many plots/graphs and considering the patterns and relationships you see. 

After you have explored completely, submit the three graphs/plots that you found most informative during your EDA process, and briefly explain what you learned from each (why you found each informative).

* * *

Adding Quality Category as a variable. If Overall Quality is 9 or 10 then its "very Good", if it is 7 or 8 then the Quality is Good, for 5-7, it is Average and for below 5, the quality is poor.

```{r}
calc_quality<-function(x)
{
  ifelse (x >=9,
    "Very Good",ifelse (x>=7 & x<9,"Good",ifelse (x>=5 & x<7,"Average",
  ifelse (x<5,"Poor","NA"))))
  }

ames_train<-cbind(ames_train,lapply(ames_train[,20], calc_quality))
colnames(ames_train)[ncol(ames_train)]<-"Quality.Category"
```

Numerical Summary

```{r}
summary1<-ames_train %>% select(price,Quality.Category) %>% group_by(Quality.Category) %>% summarize(Median_Price=median(price),Mean_Price = mean(price),Standard_Deviation_Price=sd(price))
kable(summary1)
```


```{r creategraphs}
ggplot(data=ames_train,aes(y=price,x=Quality.Category))+geom_boxplot(color = "dark green",fill="lime green",alpha = 0.5)+labs(title="BoxPlots of Price based on Overall Quality")+theme(plot.title = element_text(hjust = 0.5))+xlab("Quality Category")+ylab("Price")
```

While it is obvious that overall quality of materials and finish is a big deciding factor in the pricing of a house, I wanted to know the exact effect it has on the price. We can figure out two things from the side by side boxplots.

1. The median price of houses whose quality is Very good i.e rated 9 or 10 is almost double of the median prices of houses which are rated Good i.e. 7 or 8. This difference in median prices is much more if you see the difference between medians of Good, Average and Poor quality houses.

2. The IQRs and Standard Deviation for Good and Very Good Houses are somewhat similar and much more as compared to Average/ Poor houses. This tells us that if the quality of a  house is Good or Very Good, the significance of other factors(location,amenities etc.) is more. While for a poor or average rated house, the other factors do play a part in pricing but the variance in price range is limited. 

Based on this, I would put quality as a number 1 predictor of Price. Improving the overall quality of a house would bump the price of the house significantly. In other words taking location as a factor as an example, a very good quality house in a very good neighbourhood would have a enormous price difference to a poor quality house in the same neighbourhood. 


Location is one of the main factors that drive the price up of a house. Below I have created a side by side boxplot of the prices based on the Neighbourhood they belong to.



```{r}
ggplot(data=ames_train,aes(y=price,x=Neighborhood))+geom_boxplot(fill="Blue",color="Black",alpha=0.3)+theme(plot.title = element_text(hjust=0.5,face="bold"),axis.text.x = element_text(hjust = 0.5,angle = 90,colour = "Dark Blue",face = "bold"),panel.background = element_rect(fill="antiquewhite"),axis.text.y = element_text(color="Dark Blue",face="bold"),axis.title.y.left = element_text(face="bold"),axis.title.x.bottom = element_text(face="bold"))+labs(title="Boxplots of Price vs Neighbourhood")+ylab("Price")
```

Numerical Summary

```{r}
summary2<-ames_train %>% select(price,Neighborhood) %>% group_by(Neighborhood) %>% summarize(Median_Price=median(price),Mean_Price=mean(price),SD_Price=sd(price),IQR_Price = IQR(price)) %>% filter(Neighborhood %in% c("StoneBr","MeadowV","NridgHt"))
kable(summary2)
```

The above plot and numerical summary indicate, that StoneBR is the most expensive neighbourhood with the median price of 340691 followed closely by NridgHT. MeadowV on the other hand is the least expensive neighbourhood. So, if two identical houses are built in StoneBR and MeadowV, the builder can charge a much higher price for the house in StoneBR as compared to MeadowV.

The standard deviation and IQR suggests that StoneBR is the most heterogenous neighbourhood when it comes to price of houses. 


Similar to Overall Quality of a house in terms of material and finish, I also want to see the effect of the Overall condition on the price of a house. 

Catgorizing condition based on codebook provided

```{r}
ames_train_cond<-ames_train %>% mutate(Condition_category=ifelse(Overall.Cond>8,"Excellent",ifelse(Overall.Cond>6,"Good",ifelse(Overall.Cond>4,"Average",ifelse(Overall.Cond>2,"Fair","Poor")))))
```

```{r}
ggplot(data=ames_train_cond,aes(y=price,x=Condition_category))+geom_boxplot(color = "dark green",fill="lime green",alpha = 0.5)+labs(title="BoxPlots of Price based on Overall Condition")+theme(plot.title = element_text(hjust = 0.5))+xlab("Condition Category")+ylab("Price")
```

Contrary to the results of Price vs Overall Quality of a house, the plot of price vs Overall Condition presents a different story. The median price and the IQR of a house whose overall condition is Average is much more than all other categories. The outliers are also much higher and more for Average category houses.

This particular trend can be attributed to the following

1. Other conditions such as location and Build quality plays a much higher role in the price of a house than the Overall Condition. What this means is that buyers are willing to pay a higher price for a house whose condition is average or satisfactory as long as it is in a good locality and with a good built and quality. This also shows that condition starts playing an important role in the price, the moment it drops below average level.

2. One more thing that can be a reason for this trend is that buyers would be willing to pay a higher price if they are visually pleased with the house i.e Quality and finish of the house and the location. For instance, Buyers would be willing to pay a high price for a house that they are visually pleased with even if the condition of AC is not excellent. In some cases, they would not even notice a poor condition, if they are already pleased with the build quality and finish of the house and the location.




* * *

## Part 2 - Development and assessment of an initial model, following a semi-guided process of analysis

### Section 2.1 An Initial Model
In building a model, it is often useful to start by creating a simple, intuitive initial model based on the results of the exploratory data analysis. (Note: The goal at this stage is **not** to identify the "best" possible model but rather to choose a reasonable and understandable starting point. Later you will expand and revise this model to create your final model.

Based on your EDA, select *at most* 10 predictor variables from “ames_train” and create a linear model for `price` (or a transformed version of price) using those variables. Provide the *R code* and the *summary output table* for your model, a *brief justification* for the variables you have chosen, and a *brief discussion* of the model results in context (focused on the variables that appear to be important predictors and how they relate to sales price).

* * *

Based on the EDA plot, I have select Overall.Qual as well as Overall.Cond as two variables that affect the price of a house. Note : We saw how overall.Cond was not significant when the condition was average/good. However, it has a significant role when it is poor/average in deciding the price of a house. Apart from this, Neighborhood is another variable that has been used in the initial model. The EDA plots show a very strong relationship of price with the neighborhood a house belongs to. The three other variables, area, bedroom.AbvGr and TotRms.AbvGrd have been used as it is obvious that the price of a house has a direct relation with the area/total no of rooms/bedrooms. In other words, The bigger the house, higher is the price. 



```{r fit_model}
initial_model<-lm(log(price)~area+Neighborhood+Overall.Qual+Overall.Cond+Year.Built+Bedroom.AbvGr+TotRms.AbvGrd,data = ames_train)
summary(initial_model)
```

Residuals Plot
```{r}
ggplot(data=initial_model,aes(y=.resid,x=.fitted))+geom_point(color="maroon")+geom_hline(yintercept = 0,linetype="dashed",color="dark red")
```


* * *

The summary statistics and Residual plot of the model shows a constant variablility of the residuals. Based on the summary statistics, we can see that almost all variables have a low p-value.(Significance level : 0.05). So, I would say that this model is a good initial model to use as a starting point in building the best model for prediction of house prices. 

Note : I have used log(Price) instead of price in my model as it has a much better variability across the center line at 0 for residuals than using Price directly. For the sake of brevity, I have only shown the plot of residuals for the natural log of price as the predicted variable. 

### Section 2.2 Model Selection

Now either using `BAS` another stepwise selection procedure choose the "best" model you can, using your initial model as your starting point. Try at least two different model selection methods and compare their results. Do they both arrive at the same model or do they disagree? What do you think this means?

* * *

<B>Model selection using Stepwise backward selection</B>

Summary of Initial Model

```{r model_select}
summary(initial_model)
```

Based on this, we will eliminate TotRms.AbvGrd variable as it has the p-value of 0.358610 which is very high compared to the significance level of 0.05. 

```{r}
initial_model_Backward<-lm(formula = log(price) ~ area + Neighborhood + Overall.Qual + 
    Overall.Cond + Year.Built + Bedroom.AbvGr, 
    data = ames_train)
model_sum<-summary(initial_model_Backward)
model_sum$adj.r.squared
model_sum
```

There is not much change in the adjusted R squared and based on the p-value for all coefficient which is much lower than the significance level, we would treat this as the best model after making adjustments to the inital model based on the backward elimination method.

<B>Using BAS modelling technique</B>

Note : For Bayesian modelling, I had to take out Neighbourhood from the coefficient list as including Neighbourhood was making the calculation very resource intensive. I am working on a laptop with only 4 GB of RAM. Since, R loads all the variables into the memory, it was exceeding 4GB causing my R session to crash.(This also points out to one of the drawbacks of R as discussed in R programming course)

```{r}
initial_model_bas<-bas.lm(log(price) ~ area + Overall.Qual+Overall.Cond + Year.Built + Bedroom.AbvGr + TotRms.AbvGrd,data=ames_train,prior="BIC",modelprior = uniform())
plot(initial_model_bas)
```

Even though we were not able to include neighbourhood vraiable in our model due to hardware limitations, I have included the model in analysis in order to see how the other coefficients in Bayesian modelling compare with the other models.

The Marginal probability model and the summary of the bayesian model show that TotRms.AbvGrd coefficient should not be included in our final model.This is similar to the model that we got after we employed Backward elimination. 

Since, we were limited by our hardware for doing Bayesian Bodelling, I have decided to perform backward step AIC elimination for comparison.


```{r}
initial_model<-lm(log(price)~area+Neighborhood+Overall.Qual+Overall.Cond+Year.Built+Bedroom.AbvGr+TotRms.AbvGrd,data = ames_train)
initial_model_AIC<-step(initial_model)
summary(initial_model_AIC)
```

We can see that with AIC elimination method, we arrived at the same model with area, neighbourhood,Overall.Qual,Overall.Cond,Year.Built and Bedroom.AbvGr as the predictor variables.

So, this is consistent across all modelling techniques.

* * *

### Section 2.3 Initial Model Residuals
One way to assess the performance of a model is to examine the model's residuals. In the space below, create a residual plot for your preferred model from above and use it to assess whether your model appears to fit the data well. Comment on any interesting structure in the residual plot (trend, outliers, etc.) and briefly discuss potential implications it may have for your model and inference / prediction you might produce.

* * *

NOTE: Write your written response to section 2.3 here. Delete this note before you submit your work.

In the previous section, we arrived at the same model with all 3 modelling techniques. I have picked AIC model randomly for the residuals plot

```{r model_resid}
plot(initial_model_AIC,which=1)
```

We can see that there are three outliers with this model. Row 428,276,310

If we check these values and the Estimated Price of these houses based on our model

```{r}
kable(ames_train[c(428,276,310),])
estimated_price<-as.data.frame(exp(initial_model_AIC$fitted.values[c(428,276,310)]))
colnames(estimated_price)<-"Estimated_Price"
kable(estimated_price)
```

For row 428, the outlier makes sense as the sale condition is abnormal. Also, there is no centraliized air conditioning system


* * *

### Section 2.4 Initial Model RMSE

You can calculate it directly based on the model output. Be specific about the units of your RMSE (depending on whether you transformed your response variable). The value you report will be more meaningful if it is in the original units (dollars).

* * *

NOTE: Write your written response to section 2.4 here. Delete this note before you submit your work.


```{r model_rmse}
```

* * *

### Section 2.5 Overfitting 

The process of building a model generally involves starting with an initial model (as you have done above), identifying its shortcomings, and adapting the model accordingly. This process may be repeated several times until the model fits the data reasonably well. However, the model may do well on training data but perform poorly out-of-sample (meaning, on a dataset other than the original training data) because the model is overly-tuned to specifically fit the training data. This is called “overfitting.” To determine whether overfitting is occurring on a model, compare the performance of a model on both in-sample and out-of-sample data sets. To look at performance of your initial model on out-of-sample data, you will use the data set `ames_test`.

```{r loadtest, message = FALSE}
load("ames_test.Rdata")
```

Use your model from above to generate predictions for the housing prices in the test data set.  Are the predictions significantly more accurate (compared to the actual sales prices) for the training data than the test data?  Why or why not? Briefly explain how you determined that (what steps or processes did you use)?

* * *

NOTE: Write your written response to section 2.5 here. Delete this note before you submit your work.

```{r initmodel_test}
```

* * *

**Note to the learner:** If in real-life practice this out-of-sample analysis shows evidence that the training data fits your model a lot better than the test data, it is probably a good idea to go back and revise the model (usually by simplifying the model) to reduce this overfitting. For simplicity, we do not ask you to do this on the assignment, however.

## Part 3 Development of a Final Model

Now that you have developed an initial model to use as a baseline, create a final model with *at most* 20 variables to predict housing prices in Ames, IA, selecting from the full array of variables in the dataset and using any of the tools that we introduced in this specialization.  

Carefully document the process that you used to come up with your final model, so that you can answer the questions below.

### Section 3.1 Final Model

Provide the summary table for your model.

* * *

NOTE: Write your written response to section 3.1 here. Delete this note before you submit your work.


```{r model_playground}
```

* * *

### Section 3.2 Transformation

Did you decide to transform any variables?  Why or why not? Explain in a few sentences.

* * *

NOTE: Write your written response to section 3.2 here. Delete this note before you submit your work.

```{r model_assess}
```

* * *

### Section 3.3 Variable Interaction

Did you decide to include any variable interactions? Why or why not? Explain in a few sentences.

* * *

NOTE: Write your written response to section 3.3 here. Delete this note before you submit your work.

```{r model_inter}
```

* * *

### Section 3.4 Variable Selection

What method did you use to select the variables you included? Why did you select the method you used? Explain in a few sentences.

* * *

NOTE: Write your written response to section 3.4 here. Delete this note before you submit your work.

```{r model_select}
```

* * *

### Section 3.5 Model Testing

How did testing the model on out-of-sample data affect whether or how you changed your model? Explain in a few sentences.

* * *

NOTE: Write your written response to section 3.5 here. Delete this note before you submit your work.

```{r model_testing}
```

* * *

## Part 4 Final Model Assessment

### Section 4.1 Final Model Residual

For your final model, create and briefly interpret an informative plot of the residuals.

* * *

NOTE: Write your written response to section 4.1 here. Delete this note before you submit your work.

* * *

### Section 4.2 Final Model RMSE

For your final model, calculate and briefly comment on the RMSE.

* * *

NOTE: Write your written response to section 4.2 here. Delete this note before you submit your work.

* * *

### Section 4.3 Final Model Evaluation

What are some strengths and weaknesses of your model?

* * *

NOTE: Write your written response to section 4.3 here. Delete this note before you submit your work.

* * *

### Section 4.4 Final Model Validation

Testing your final model on a separate, validation data set is a great way to determine how your model will perform in real-life practice. 

You will use the “ames_validation” dataset to do some additional assessment of your final model. Discuss your findings, be sure to mention:
* What is the RMSE of your final model when applied to the validation data?  
* How does this value compare to that of the training data and/or testing data?
* What percentage of the 95% predictive confidence (or credible) intervals contain the true price of the house in the validation data set?  
* From this result, does your final model properly reflect uncertainty?

```{r loadvalidation, message = FALSE}
load("ames_validation.Rdata")
```

* * *

NOTE: Write your written response to section 4.4 here. Delete this note before you submit your work.

```{r model_validate}
```

* * *

## Part 5 Conclusion

Provide a brief summary of your results, and a brief discussion of what you have learned about the data and your model. 

* * *

NOTE: Write your written response to part 5 here. Delete this note before you submit your work.

* * *
